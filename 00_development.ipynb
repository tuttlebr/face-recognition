{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoke Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from utils.face_utils import FaceDetector, index_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/jovyan/data-vol-1/\"\n",
    "images_root_dir = \"/home/jovyan/brandon_face_recognition/\"\n",
    "\n",
    "face_det_model_path = os.path.join(root_dir, \"dlib_models/mmod_human_face_detector.dat\")\n",
    "predictor_path = os.path.join(root_dir, \"dlib_models/shape_predictor_68_face_landmarks.dat\")\n",
    "face_rec_model_path = os.path.join(root_dir, \"dlib_models/dlib_face_recognition_resnet_model_v1.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Tensorflow CUDA devices available: 2\n",
      "INFO:root:dlib CUDA devices available: 2\n",
      "INFO:root:Using Convolutional Neural Network method.\n"
     ]
    }
   ],
   "source": [
    "fd = FaceDetector(\n",
    "    face_det_model_path=face_det_model_path,\n",
    "    predictor_path=predictor_path,\n",
    "    face_rec_model_path=face_rec_model_path,\n",
    "    images_root_dir=images_root_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Found 5 images\n"
     ]
    }
   ],
   "source": [
    "fd.collect_image_file_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jovyan/brandon_face_recognition/sample_images/tos0.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/sample_images/tos1.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/sample_images/tos2.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/sample_images/tos3.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/sample_images/tos4.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.images_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4884e987a9274709b6b16e1eeef8e3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Isolating faces in images...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fd.load_images_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"file_path\": \"/home/jovyan/brandon_face_recognition/sample_images/tos0.jpg\", \"face_count\": 6, \"face_metadata\": [{\"id\": \"face_0\", \"confidence\": 1.0911993980407715, \"dets_ltrb\": [1220, 127, 1384, 291]}, {\"id\": \"face_1\", \"confidence\": 1.069895625114441, \"dets_ltrb\": [740, 148, 937, 344]}, {\"id\": \"face_2\", \"confidence\": 1.0639574527740479, \"dets_ltrb\": [1477, 327, 1673, 524]}, {\"id\": \"face_3\", \"confidence\": 1.055281400680542, \"dets_ltrb\": [507, 77, 670, 241]}, {\"id\": \"face_4\", \"confidence\": 1.0537011623382568, \"dets_ltrb\": [222, 128, 419, 324]}, {\"id\": \"face_5\", \"confidence\": 1.0359842777252197, \"dets_ltrb\": [1815, 247, 2012, 444]}]}\n",
      "\n",
      "{\"file_path\": \"/home/jovyan/brandon_face_recognition/sample_images/tos1.jpg\", \"face_count\": 4, \"face_metadata\": [{\"id\": \"face_0\", \"confidence\": 1.103255033493042, \"dets_ltrb\": [120, 444, 215, 538]}, {\"id\": \"face_1\", \"confidence\": 1.0882455110549927, \"dets_ltrb\": [321, 89, 416, 183]}, {\"id\": \"face_2\", \"confidence\": 1.0829507112503052, \"dets_ltrb\": [100, 180, 179, 259]}, {\"id\": \"face_3\", \"confidence\": 1.0792239904403687, \"dets_ltrb\": [331, 463, 426, 558]}]}\n",
      "\n",
      "{\"file_path\": \"/home/jovyan/brandon_face_recognition/sample_images/tos2.jpg\", \"face_count\": 3, \"face_metadata\": [{\"id\": \"face_0\", \"confidence\": 1.0638675689697266, \"dets_ltrb\": [148, 76, 227, 155]}, {\"id\": \"face_1\", \"confidence\": 0.9615164995193481, \"dets_ltrb\": [644, 20, 723, 99]}, {\"id\": \"face_2\", \"confidence\": 0.8125666379928589, \"dets_ltrb\": [420, 188, 499, 267]}]}\n",
      "\n",
      "{\"file_path\": \"/home/jovyan/brandon_face_recognition/sample_images/tos3.jpg\", \"face_count\": 4, \"face_metadata\": [{\"id\": \"face_0\", \"confidence\": 1.0912861824035645, \"dets_ltrb\": [651, 179, 765, 292]}, {\"id\": \"face_1\", \"confidence\": 1.0693566799163818, \"dets_ltrb\": [305, 190, 419, 304]}, {\"id\": \"face_2\", \"confidence\": 1.0430654287338257, \"dets_ltrb\": [532, 175, 627, 270]}, {\"id\": \"face_3\", \"confidence\": 0.9868757724761963, \"dets_ltrb\": [101, 252, 195, 347]}]}\n",
      "\n",
      "{\"file_path\": \"/home/jovyan/brandon_face_recognition/sample_images/tos4.jpg\", \"face_count\": 2, \"face_metadata\": [{\"id\": \"face_0\", \"confidence\": 1.0612872838974, \"dets_ltrb\": [713, 185, 909, 382]}, {\"id\": \"face_1\", \"confidence\": 1.0515563488006592, \"dets_ltrb\": [339, 284, 475, 420]}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('sample.json')\n",
    "for i in f:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd.read_manifest('sample.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0eebfcd8de34aec9a5e1aef290f015b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "getting facial descriptions...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fd.describe_from_manifest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Number of clusters: 8\n"
     ]
    }
   ],
   "source": [
    "fd.cluster_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd.save_cluster_chips()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jovyan/brandon_face_recognition/face_chip_clusters/0/face_0.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/face_chip_clusters/0/face_11.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/face_chip_clusters/0/face_14.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/face_chip_clusters/0/face_7.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/face_chip_clusters/1/face_1.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/face_chip_clusters/1/face_12.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/face_chip_clusters/1/face_17.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/face_chip_clusters/1/face_9.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/face_chip_clusters/2/face_2.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/face_chip_clusters/2/face_8.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/face_chip_clusters/3/face_10.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/face_chip_clusters/3/face_18.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/face_chip_clusters/3/face_3.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/face_chip_clusters/3/face_6.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/face_chip_clusters/4/face_4.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/face_chip_clusters/5/face_5.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/face_chip_clusters/6/face_13.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/face_chip_clusters/6/face_15.jpg',\n",
       " '/home/jovyan/brandon_face_recognition/face_chip_clusters/7/face_16.jpg']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_directory(\"/home/jovyan/brandon_face_recognition/face_chip_clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
